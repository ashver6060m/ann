import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_error

# data = pd.read_csv("winequality-red.csv", sep=';')

# X = data.drop("quality", axis=1).values  
# y = data["quality"].values              

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

num_centers = 10
kmeans = KMeans(n_clusters=num_centers, random_state=0)
kmeans.fit(X_train)
centers = kmeans.cluster_centers_

dists = []
for i in range(num_centers):
    for j in range(i + 1, num_centers):
        dists.append(np.linalg.norm(centers[i] - centers[j]))
sigma = np.mean(dists)

def rbf(x, center, sigma):
    return np.exp(-np.linalg.norm(x - center) ** 2 / (2 * sigma ** 2))

def compute_rbf_features(X, centers, sigma):
    G = np.zeros((X.shape[0], len(centers)))
    for i in range(X.shape[0]):
        for j in range(len(centers)):
            G[i, j] = rbf(X[i], centers[j], sigma)
    return G

G_train = compute_rbf_features(X_train, centers, sigma)
G_test = compute_rbf_features(X_test, centers, sigma)

weights = np.linalg.pinv(G_train).dot(y_train)

y_pred = G_test.dot(weights)
mse = mean_squared_error(y_test, y_pred)

print("Mean Squared Error on Test Set:", mse)
