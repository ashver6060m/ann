import numpy as np

def activation(z):
    return 1 if z >= 0 else 0

def perceptron(X_train, y_train, bias, epochs, learning_rate):
    weights = np.zeros(len(X_train[0])) 
    for _ in range(epochs):
        for i in range(len(X_train)):
            z = np.dot(X_train[i], weights) + bias 
            y_pred = activation(z)
            error = y_train[i] - y_pred            
            for j in range(len(weights)):
                weights[j] += learning_rate * error * X_train[i][j]
            bias += learning_rate * error  
    return weights, bias

dataset = np.array([
    [2.7, 2.5], [1.4, 2.3], [3.3, 4.4], [1.3, 1.8], [3.0, 3.0],
    [7.6, 2.7], [5.3, 2.0], [6.9, 1.7], [7.6, 3.5], [8.6, -0.2]
])
y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])

weights,bias = perceptron(dataset,y, 0.01, 10, 0.001)
print(weights)
print(bias)
